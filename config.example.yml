# Bryti configuration
# Copy to data/config.yml and fill in your values.
# ${VAR} references are substituted from environment variables.

agent:
  name: "Bryti"

  # Your additions to the system prompt. This is where you tell the agent who
  # you are, how you want it to behave, and what it should know about your life.
  # The framework adds memory, tool docs, and all other sections automatically.
  # This part is yours.
  system_prompt: |
    You are Bryti, a personal AI assistant.

    About me:
    - My name is [Your Name]. I live in [City/Country].
    - I work as [your role] at [company/org].
    - My main projects right now: [list a few].

    How I want you to work:
    - Be direct. Don't pad responses with filler.
    - When I ask you to remember something, actually store it. Don't just say "noted."
    - If you're unsure about something, say so. Don't guess and present it as fact.
    - Proactively remind me of things I've told you about, when relevant.
    - When researching something, give me a summary first, then ask if I want details.

  # Primary model. Format: provider/model-id
  # Option 1: Anthropic OAuth (Claude Pro/Max subscription, no API key needed)
  # Requires pi CLI login first: `pi login anthropic`
  model: "anthropic/claude-sonnet-4-6"

  # Tried in order when primary model fails
  fallback_models:
    - "opencode/minimax-m2.5-free"
    - "opencode/kimi-k2.5-free"

  # IANA timezone for projection scheduling and display
  timezone: "Europe/Amsterdam"

  # Model for the background reflection pass (defaults to primary model).
  # Set a cheaper model here to save tokens on background work.
  # reflection_model: "opencode/minimax-m2.5-free"

# ---------------------------------------------------------------------------
# Channels — enable at least one
# ---------------------------------------------------------------------------

telegram:
  token: ${TELEGRAM_BOT_TOKEN}
  allowed_users: []  # Telegram user IDs. Empty = allow all (not recommended).

# WhatsApp via baileys (no Meta Business API). QR code auth on first run.
# allowed_users: phone numbers in international format without + (e.g., 31612345678)
whatsapp:
  enabled: false
  allowed_users: []

# ---------------------------------------------------------------------------
# Model providers
# ---------------------------------------------------------------------------

models:
  providers:
    # context_window and max_tokens are optional on every model.
    # Defaults: 200K context, 32K output. Only set them when a model differs.
    # Only list the models you actually use in agent.model / fallback_models.

    # Anthropic OAuth — uses your Claude Pro or Max subscription.
    # No api_key needed; bryti reads the OAuth token from ~/.pi/agent/auth.json.
    # One-time setup: install pi (`npm i -g @mariozechner/pi-coding-agent`)
    # and run `pi login anthropic`. Opens a browser, token is stored locally.
    - name: anthropic
      base_url: ""
      api: anthropic-messages
      api_key: ""
      models:
        - id: "claude-sonnet-4-6"
          context_window: 200000
          max_tokens: 64000

    # Free open models via opencode.ai (no subscription, no API key)
    - name: opencode
      base_url: https://opencode.ai/zen/v1
      api: openai-responses
      api_key: "public"
      models:
        - id: "minimax-m2.5-free"
          name: "MiniMax M2.5 (Free)"
          api: openai-completions
          context_window: 200000
          max_tokens: 32000
          compat:
            maxTokensField: max_tokens
        - id: "kimi-k2.5-free"
          name: "Kimi K2.5 (Free)"
          api: openai-completions
          max_tokens: 32000
          compat:
            maxTokensField: max_tokens

    # --- More providers (uncomment and add your keys) ---

    # Anthropic API key (alternative to OAuth above)
    # - name: anthropic
    #   api: anthropic-messages
    #   api_key: ${ANTHROPIC_API_KEY}
    #   models:
    #     - id: "claude-sonnet-4-6"
    #       context_window: 200000
    #       max_tokens: 64000

    # OpenRouter — access 200+ models with one API key
    # - name: openrouter
    #   base_url: https://openrouter.ai/api/v1
    #   api_key: ${OPENROUTER_API_KEY}
    #   models:
    #     - id: "anthropic/claude-sonnet-4-6"
    #       context_window: 200000
    #       max_tokens: 64000

    # Google Gemini
    # - name: google
    #   base_url: https://generativelanguage.googleapis.com/v1beta/openai
    #   api_key: ${GOOGLE_API_KEY}
    #   models:
    #     - id: "gemini-2.5-flash"
    #       context_window: 1048576
    #       max_tokens: 65536

    # Ollama (local or remote)
    # - name: ollama
    #   base_url: http://localhost:11434/v1
    #   api_key: "ollama"
    #   models:
    #     - id: "qwen3:32b"

    # Together AI
    # - name: together
    #   base_url: https://api.together.xyz/v1
    #   api_key: ${TOGETHER_API_KEY}
    #   models:
    #     - id: "Qwen/Qwen3-235B-A22B"

# ---------------------------------------------------------------------------
# Tools
# ---------------------------------------------------------------------------

tools:
  # Web search for workers. Set brave_api_key OR searxng_url (not both).
  # If both are set, Brave takes priority.
  # If neither is set, web search is disabled for workers.
  web_search:
    # Option A: Brave Search API — free tier 2000 queries/month, no self-hosting.
    #           Get a key at https://api.search.brave.com/
    # brave_api_key: "${BRAVE_API_KEY}"

    # Option B: SearXNG — self-hosted or public instance, no API key needed.
    searxng_url: "https://searx.be"

  # fetch_url:
  #   timeout_ms: 10000    # default: 10s

  # files:
  #   base_dir: ./data/files  # default

  workers:
    max_concurrent: 3

# ---------------------------------------------------------------------------
# Integrations (optional)
#
# Values here are injected into process.env at startup so extensions can
# read them without separate .env entries.
#
# Convention: integrations.<name>.<key> becomes the env var NAME_KEY (uppercased).
# Example: integrations.hedgedoc.url → HEDGEDOC_URL
#
# Secrets (API keys, tokens) should still use ${VAR} substitution so they
# stay in .env and out of config.yml.
# ---------------------------------------------------------------------------

# integrations:
#   hedgedoc:
#     url: "http://hedgedoc:3000"           # internal Docker network URL
#     public_url: "https://docs.example.com" # user-facing URL for shared links
#
#   # Any future integration follows the same pattern:
#   # my_service:
#   #   url: "https://api.example.com"
#   #   api_key: "${MY_SERVICE_API_KEY}"    # secret stays in .env

# ---------------------------------------------------------------------------
# Scheduled prompts (optional)
# ---------------------------------------------------------------------------

cron: []
  # - schedule: "0 8 * * *"
  #   message: "Good morning! Brief me on anything I need to know today."
  # - schedule: "0 18 * * 1-5"
  #   message: "Summarize what we discussed today and update memory with action items."

# ---------------------------------------------------------------------------
# Trust levels (runtime permissions for elevated tools)
# ---------------------------------------------------------------------------

# Extension tools (shell_exec, http_request, etc.) require approval before
# first use. Pre-approve tools here to skip the permission prompt.
# trust:
#   approved_tools:
#     - shell_exec
#     - http_request
#     - weather_weert

# ---------------------------------------------------------------------------
# Active hours (optional — limits when the scheduler can send messages)
# ---------------------------------------------------------------------------

# active_hours:
#   start: "08:00"
#   end: "23:00"
