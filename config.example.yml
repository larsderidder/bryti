# Bryti configuration
# Copy to data/config.yml and fill in your values.
# ${VAR} references are substituted from environment variables.

agent:
  name: "Bryti"

  # Your additions to the system prompt. Persona, standing instructions, context
  # about you and your work. The framework adds memory, tool descriptions, and
  # all other sections automatically.
  system_prompt: |
    You are Bryti, a personal AI assistant. You are concise and practical.

  # Primary model. Format: provider/model-id
  # Option 1: Anthropic OAuth (Claude Pro/Max subscription, no API key needed)
  # Requires pi CLI login first: `pi login anthropic`
  model: "anthropic/claude-sonnet-4-20250514"

  # Tried in order when primary model fails
  fallback_models:
    - "opencode/minimax-m2.5-free"
    - "opencode/kimi-k2.5-free"

  # Option 2: Free models only (no subscription needed)
  # model: "opencode/minimax-m2.5-free"
  # fallback_models:
  #   - "opencode/kimi-k2.5-free"

  # IANA timezone for projection scheduling and display
  timezone: "Europe/Amsterdam"

  # Model for the background reflection pass (defaults to primary model).
  # Set a cheaper model here to save tokens on background work.
  # reflection_model: "opencode/minimax-m2.5-free"

# ---------------------------------------------------------------------------
# Channels — enable at least one
# ---------------------------------------------------------------------------

telegram:
  token: ${TELEGRAM_BOT_TOKEN}
  allowed_users: []  # Telegram user IDs. Empty = allow all (not recommended).

# WhatsApp via baileys (no Meta Business API). QR code auth on first run.
# allowed_users: phone numbers in international format without + (e.g., 31612345678)
whatsapp:
  enabled: false
  allowed_users: []

# ---------------------------------------------------------------------------
# Model providers
# ---------------------------------------------------------------------------

models:
  providers:
    # Anthropic OAuth — uses your Claude Pro or Max subscription.
    # No api_key needed; bryti reads the OAuth token from ~/.pi/agent/auth.json.
    # One-time setup: install the pi CLI and run `pi login anthropic`.
    # This opens a browser for Anthropic OAuth; the token is stored locally.
    - name: anthropic
      base_url: ""
      api: anthropic-messages
      api_key: ""
      models:
        - id: "claude-sonnet-4-20250514"
          name: "Claude Sonnet 4.5"
          context_window: 200000
          max_tokens: 16384
        - id: "claude-opus-4-20250514"
          name: "Claude Opus 4"
          context_window: 200000
          max_tokens: 16384

    # Free open models via opencode.ai (no subscription, no API key)
    - name: opencode
      base_url: https://opencode.ai/zen/v1
      api: openai-responses
      api_key: "public"
      models:
        - id: "minimax-m2.5-free"
          name: "MiniMax M2.5 (Free)"
          api: openai-completions
          context_window: 200000
          max_tokens: 32000
          compat:
            maxTokensField: max_tokens
        - id: "kimi-k2.5-free"
          name: "Kimi K2.5 (Free)"
          api: openai-completions
          context_window: 128000
          max_tokens: 32000
          compat:
            maxTokensField: max_tokens

    # --- Paid API providers (uncomment and add your keys) ---

    # Anthropic API key (alternative to OAuth above)
    # - name: anthropic
    #   base_url: ""
    #   api: anthropic-messages
    #   api_key: ${ANTHROPIC_API_KEY}
    #   models:
    #     - id: "claude-sonnet-4-20250514"
    #       name: "Claude Sonnet 4.5"
    #       context_window: 200000
    #       max_tokens: 16384

    # OpenRouter — access 200+ models with one API key
    # - name: openrouter
    #   base_url: https://openrouter.ai/api/v1
    #   api_key: ${OPENROUTER_API_KEY}
    #   models:
    #     - id: "anthropic/claude-sonnet-4"
    #       name: "Claude Sonnet 4 (OpenRouter)"
    #       context_window: 200000
    #       max_tokens: 16384

    # Google Gemini
    # - name: google
    #   base_url: https://generativelanguage.googleapis.com/v1beta/openai
    #   api_key: ${GOOGLE_API_KEY}
    #   models:
    #     - id: "gemini-2.5-flash"
    #       name: "Gemini 2.5 Flash"
    #       context_window: 1048576
    #       max_tokens: 65536

    # Ollama (local or remote)
    # - name: ollama
    #   base_url: http://localhost:11434/v1
    #   api_key: "ollama"
    #   models:
    #     - id: "qwen3:32b"
    #       name: "Qwen 3 32B"
    #       context_window: 131072
    #       max_tokens: 8192

    # Together AI
    # - name: together
    #   base_url: https://api.together.xyz/v1
    #   api_key: ${TOGETHER_API_KEY}
    #   models:
    #     - id: "Qwen/Qwen3-235B-A22B"
    #       name: "Qwen 3 235B"
    #       context_window: 131072
    #       max_tokens: 8192

# ---------------------------------------------------------------------------
# Tools
# ---------------------------------------------------------------------------

tools:
  # Web search via SearXNG (used by workers for web research).
  # Self-host SearXNG or use a public instance.
  web_search:
    enabled: true
    searxng_url: "https://searx.be"   # Replace with your own SearXNG instance

  fetch_url:
    enabled: true
    timeout_ms: 10000

  files:
    enabled: true
    base_dir: ./data/files

  workers:
    max_concurrent: 3

# ---------------------------------------------------------------------------
# Integrations (optional)
#
# Values here are injected into process.env at startup so extensions can
# read them without separate .env entries.
#
# Convention: integrations.<name>.<key> becomes the env var NAME_KEY (uppercased).
# Example: integrations.hedgedoc.url → HEDGEDOC_URL
#
# Secrets (API keys, tokens) should still use ${VAR} substitution so they
# stay in .env and out of config.yml.
# ---------------------------------------------------------------------------

# integrations:
#   hedgedoc:
#     url: "http://hedgedoc:3000"           # internal Docker network URL
#     public_url: "https://docs.example.com" # user-facing URL for shared links
#
#   # Any future integration follows the same pattern:
#   # my_service:
#   #   url: "https://api.example.com"
#   #   api_key: "${MY_SERVICE_API_KEY}"    # secret stays in .env

# ---------------------------------------------------------------------------
# Scheduled prompts (optional)
# ---------------------------------------------------------------------------

cron: []
  # - schedule: "0 8 * * *"
  #   message: "Good morning! Brief me on anything I need to know today."
  # - schedule: "0 18 * * 1-5"
  #   message: "Summarize what we discussed today and update memory with action items."

# ---------------------------------------------------------------------------
# Trust levels (runtime permissions for elevated tools)
# ---------------------------------------------------------------------------

# Extension tools (shell_exec, http_request, etc.) require approval before
# first use. Pre-approve tools here to skip the permission prompt.
# trust:
#   approved_tools:
#     - shell_exec
#     - http_request
#     - weather_weert

# ---------------------------------------------------------------------------
# Active hours (optional — limits when the scheduler can send messages)
# ---------------------------------------------------------------------------

# active_hours:
#   start: "08:00"
#   end: "23:00"
