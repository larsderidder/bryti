# Bryti configuration
# Copy to data/config.yml and fill in your values.
# ${VAR} references are substituted from environment variables.

agent:
  name: "Bryti"

  # System prompt. Memory contents, tool listings, extensions, and projections
  # are injected automatically; this is the behavioral core. Personal details
  # about you are best shared in conversation; the agent stores them in core
  # memory and keeps them across sessions.
  system_prompt: |
    You are Bryti, a personal AI assistant. You run on the pi agent framework
    with persistent memory and tool-calling capabilities. You are concise,
    practical, and honest about what you can and cannot do.

    ## Your memory
    Your core memory (shown below) persists across conversations. Update it when
    you learn something worth keeping: user preferences, facts, ongoing projects,
    recurring topics. Do this proactively without telling the user unless asked.

    Archival memory is for details that don't need to be always visible but should
    be searchable later.

    ## Projection memory
    Projections are your forward-looking memory. Store anything about the
    future: appointments, deadlines, plans, reminders, commitments. Your
    current projections are shown below; use `projection_list` to see more.

    Guidelines:
    - Store ALL items, even far-future ones. If unsure about timing, use
      resolution "month" or "someday"
    - Connect new information to existing projections when you see a link
    - When the user postpones a discussion, create a separate projection for
      each distinct topic being deferred
    - ALWAYS populate the context field with keywords to search archival
      memory with and a brief description of why this matters
    - Before creating a projection, search archival memory first to find
      existing relevant context. Note key terms in the context field so you
      can find them again at activation time
    - If you just discussed something worth projecting, archive the key
      points first, then create the projection referencing what you archived
    - When a projection activates, search archival memory for related context
      before responding. Projections are the "what" and "when"; archival
      memory holds the "why"

    ## What you cannot do
    - You cannot modify your own source code or core configuration
    - You cannot access the internet directly. Use worker_dispatch for any
      web research.

  # Primary model. Format: provider/model-id
  # Option 1: Anthropic OAuth (Claude Pro/Max subscription, no API key needed)
  # Requires pi CLI login first: `pi login anthropic`
  model: "anthropic/claude-sonnet-4-6"

  # Tried in order when primary model fails
  fallback_models:
    - "opencode/minimax-m2.5-free"
    - "opencode/kimi-k2.5-free"

  # IANA timezone for projection scheduling and display
  timezone: "Europe/Amsterdam"

  # Model for the background reflection pass (defaults to primary model).
  # Set a cheaper model here to save tokens on background work.
  # reflection_model: "opencode/minimax-m2.5-free"

# ---------------------------------------------------------------------------
# Channels (enable at least one)
# ---------------------------------------------------------------------------

telegram:
  token: ${TELEGRAM_BOT_TOKEN}
  allowed_users: []  # Telegram user IDs. Empty = allow all (not recommended).

# WhatsApp via baileys (no Meta Business API). QR code auth on first run.
# allowed_users: phone numbers in international format without + (e.g., 31612345678)
whatsapp:
  enabled: false
  allowed_users: []

# ---------------------------------------------------------------------------
# Model providers
# ---------------------------------------------------------------------------

models:
  providers:
    # context_window and max_tokens are optional on every model.
    # Defaults: 200K context, 32K output. Only set them when a model differs.
    # Only list the models you actually use in agent.model / fallback_models.

    # Anthropic OAuth: uses your Claude Pro or Max subscription.
    # No api_key needed; bryti reads the OAuth token from ~/.pi/agent/auth.json.
    # One-time setup: install pi (`npm i -g @mariozechner/pi-coding-agent`)
    # and run `pi login anthropic`. Opens a browser, token is stored locally.
    - name: anthropic
      base_url: ""
      api: anthropic-messages
      api_key: ""
      models:
        - id: "claude-sonnet-4-6"
          context_window: 200000
          max_tokens: 64000

    # Free open models via opencode.ai (no subscription, no API key)
    - name: opencode
      base_url: https://opencode.ai/zen/v1
      api: openai-responses
      api_key: "public"
      models:
        - id: "minimax-m2.5-free"
          name: "MiniMax M2.5 (Free)"
          api: openai-completions
          context_window: 200000
          max_tokens: 32000
          compat:
            maxTokensField: max_tokens
        - id: "kimi-k2.5-free"
          name: "Kimi K2.5 (Free)"
          api: openai-completions
          context_window: 128000
          max_tokens: 32000
          compat:
            maxTokensField: max_tokens

    # --- More providers (uncomment and add your keys) ---

    # Anthropic API key (alternative to OAuth above)
    # - name: anthropic
    #   api: anthropic-messages
    #   api_key: ${ANTHROPIC_API_KEY}
    #   models:
    #     - id: "claude-sonnet-4-6"
    #       context_window: 200000
    #       max_tokens: 64000

    # OpenRouter: access 200+ models with one API key
    # - name: openrouter
    #   base_url: https://openrouter.ai/api/v1
    #   api_key: ${OPENROUTER_API_KEY}
    #   models:
    #     - id: "anthropic/claude-sonnet-4-6"
    #       context_window: 200000
    #       max_tokens: 64000

    # Google Gemini
    # - name: google
    #   base_url: https://generativelanguage.googleapis.com/v1beta/openai
    #   api_key: ${GOOGLE_API_KEY}
    #   models:
    #     - id: "gemini-2.5-flash"
    #       context_window: 1048576
    #       max_tokens: 65536

    # Ollama (local or remote)
    # - name: ollama
    #   base_url: http://localhost:11434/v1
    #   api_key: "ollama"
    #   models:
    #     - id: "qwen3:32b"

    # Together AI
    # - name: together
    #   base_url: https://api.together.xyz/v1
    #   api_key: ${TOGETHER_API_KEY}
    #   models:
    #     - id: "Qwen/Qwen3-235B-A22B"

# ---------------------------------------------------------------------------
# Tools
# ---------------------------------------------------------------------------

tools:
  # Web search for workers. Set brave_api_key OR searxng_url (not both).
  # If both are set, Brave takes priority.
  # If neither is set, web search is disabled for workers.
  web_search:
    # Option A: Brave Search API. Free tier: 2000 queries/month, no self-hosting.
    #           Get a key at https://api.search.brave.com/
    # brave_api_key: "${BRAVE_API_KEY}"

    # Option B: SearXNG. Self-hosted or public instance, no API key needed.
    searxng_url: "https://searx.be"

  # fetch_url:
  #   timeout_ms: 10000    # default: 10s

  # files:
  #   base_dir: ./data/files  # default

  workers:
    max_concurrent: 3
    # Default model for background workers. Falls back to the first
    # fallback_model, then the primary agent model.
    # model: "opencode/minimax-m2.5-free"

    # Named worker types. The agent selects a type when dispatching to get
    # preset defaults for model, tools, and timeout. Explicit parameters on
    # the dispatch call still override type defaults.
    # The agent can also define new types by editing this file and restarting.
    # types:
    #   research:
    #     description: "Web research and content gathering"
    #     model: "opencode/minimax-m2.5-free"
    #     tools: [web_search, fetch_url]
    #     timeout_seconds: 3600
    #   analysis:
    #     description: "Deep analysis using a stronger model"
    #     model: "anthropic/claude-sonnet-4-6"
    #     tools: [fetch_url]
    #     timeout_seconds: 1800

# ---------------------------------------------------------------------------
# Integrations (optional)
#
# Values here are injected into process.env at startup so extensions can
# read them without separate .env entries.
#
# Convention: integrations.<name>.<key> becomes the env var NAME_KEY (uppercased).
# Example: integrations.hedgedoc.url â†’ HEDGEDOC_URL
#
# Secrets (API keys, tokens) should still use ${VAR} substitution so they
# stay in .env and out of config.yml.
# ---------------------------------------------------------------------------

# integrations:
#   hedgedoc:
#     url: "http://hedgedoc:3000"           # internal Docker network URL
#     public_url: "https://docs.example.com" # user-facing URL for shared links
#
#   # Any future integration follows the same pattern:
#   # my_service:
#   #   url: "https://api.example.com"
#   #   api_key: "${MY_SERVICE_API_KEY}"    # secret stays in .env

# ---------------------------------------------------------------------------
# Scheduled prompts (optional)
# ---------------------------------------------------------------------------

cron: []
  # - schedule: "0 8 * * *"
  #   message: "Good morning! Brief me on anything I need to know today."
  # - schedule: "0 18 * * 1-5"
  #   message: "Summarize what we discussed today and update memory with action items."

# ---------------------------------------------------------------------------
# Trust levels (runtime permissions for elevated tools)
# ---------------------------------------------------------------------------

# Extension tools (shell_exec, http_request, etc.) require approval before
# first use. Pre-approve tools here to skip the permission prompt.
# trust:
#   approved_tools:
#     - shell_exec
#     - http_request
#     - weather_weert

# ---------------------------------------------------------------------------
# Active hours (optional; limits when the scheduler can send messages)
# ---------------------------------------------------------------------------

# active_hours:
#   start: "08:00"
#   end: "23:00"
